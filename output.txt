
Total lines in captions file: 8091

Sample caption lines (randomly selected):
Line 1: /kaggle/input/flickr8k/Images/2765029348_667111fc30.jpg, <start> A bikers flips upside down . <end>
Line 2: /kaggle/input/flickr8k/Images/317109978_cb557802e1.jpg, <start> A brown and white pitbull , with a black collar , is about to leap over a branch <end>
Line 3: /kaggle/input/flickr8k/Images/2823200990_7b02b7cc36.jpg, <start> A boy jumping off a chair . <end>
Line 4: /kaggle/input/flickr8k/Images/1015584366_dfcec3c85a.jpg, <start> A black dog leaps over a log . <end>
Line 5: /kaggle/input/flickr8k/Images/482047956_9a29e9cee6.jpg, <start> A group of girls are riding on a roller coaster . <end>

![Output 1](outputs/outputimage1.png) 

Vocabulary size: 9123

Sample caption sequence: [   3    2   46    6    2   96  177    9  124   57    2  405   14  396
    6   31 5285  698    5    4    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0]

Training dataset size: 31989
Validation dataset size: 8005

Model: "inception_v3"
Total params: 21,802,784 (83.17 MB)
Trainable params: 0 (0.00 B)
Non-trainable params: 21,802,784 (83.17 MB)

Extracted training features shape: (31989, 2048)
Extracted validation features shape: (8005, 2048)

Features saved successfully.

Epoch 1/10
1996/1996 [==============================] - 6s 3ms/step - loss: 3.2 - accuracy: 0.22
Epoch 2/10
1996/1996 [==============================] - 5s 3ms/step - loss: 2.9 - accuracy: 0.28
...
Epoch 10/10
1996/1996 [==============================] - 5s 3ms/step - loss: 2.5 - accuracy: 0.35

Validation Loss: 2.47
Validation Accuracy: 0.36

Predicted Caption for test image: 
